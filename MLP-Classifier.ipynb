{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 â€” MLP Classifier\n",
    "\n",
    "Team Name: JAKH\n",
    "\n",
    "Author:\n",
    " 1. Jaya Krishna Kalavakuri (026374853)\n",
    "    Contact : JayaKrishna.Kalavakuri@student.csulb.edu\n",
    " 2. Akhil Varupula (025534780)\n",
    "    Contact : Akhil.Varupula@student.csulb.edu\n",
    " 3. Kiran Panjam (026642549)\n",
    "    Contact : Kiran.Panjam01@student.csulb.edu\n",
    " 4. Haritha Nimmagadda (026636140)\n",
    "    Contact : Haritha.Nimmagadda@student.csulb.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "from eiffel2 import builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = [] #Dataset\n",
    "X_id = [] #Input id\n",
    "X_input = [] #Input data\n",
    "y_label = [] #class\n",
    "\n",
    "f = open(\"Dataset.txt\", \"r\")    #Opening Dataset.txt to read it's contents\n",
    "for x in f:\n",
    "    data = re.sub(r'[()]', '', x)    #Reading Data with \"(\" and \")\"\n",
    "    data = data.split()\n",
    "    Dataset.append(data)\n",
    "random.shuffle(Dataset)            #Shuffling Data\n",
    "for data in Dataset:\n",
    "    X_id.append(int(data[0])) #sepqrating data by column into three different variable.\n",
    "    num = []\n",
    "    for i in data[1:len(data) - 1]:\n",
    "        num.append(int(i))\n",
    "    X_input.append(num)\n",
    "    y_label.append(int(data[len(data) - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_input)\n",
    "X = X.astype(np.float)     #Converting lists into arrays\n",
    "y_val = np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.isnan(X).any()):          #Checking for NaN values in the Input Data.\n",
    "    for i in range(np.shape(X)[0]):\n",
    "        for j in range(np.shape(X)[1]):\n",
    "            if (np.isnan(X[i][j])):\n",
    "                X[i][j] = random.randint(np.nanmin(X), np.nanmax(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52083333, 0.75      , 0.95698925, 0.63541667, 0.57291667,\n",
       "        0.53125   , 0.375     , 0.08333333, 0.03125   , 0.20833333],\n",
       "       [0.72916667, 0.875     , 0.41935484, 0.72916667, 0.51041667,\n",
       "        0.52083333, 0.75      , 0.92708333, 0.63541667, 0.53125   ],\n",
       "       [0.26041667, 0.94791667, 0.1827957 , 0.94791667, 0.66666667,\n",
       "        0.90625   , 0.96875   , 0.15625   , 0.96875   , 0.46875   ],\n",
       "       [0.65625   , 0.375     , 0.79569892, 0.09375   , 0.19791667,\n",
       "        0.80208333, 0.95833333, 0.64583333, 0.5625    , 0.60416667],\n",
       "       [0.5625    , 0.55208333, 0.74193548, 0.44791667, 0.28125   ,\n",
       "        0.89583333, 0.        , 0.59375   , 0.125     , 0.54166667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_data(X):               #Normalizing Input Data to range[0,1]\n",
    "    for i in range(np.shape(X)[1]):\n",
    "        max_ = max(X[:,i])\n",
    "        min_ = min(X[:,i])\n",
    "        for j in range(np.shape(X)[0]):\n",
    "            X[j][i] = (X[j][i] - min_)/(max_ - min_)\n",
    "    return X\n",
    "\n",
    "X = normalize_data(X)\n",
    "X[:5]                  #Normalized Input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.isnan(y_val).any()):         #Checking for NaN values in Class values\n",
    "    for i in range(np.shape(y_val)[0]):\n",
    "        if (np.isnan(y_val[i])):\n",
    "            y_val[i] = random.randint(np.nanmin(y_val), np.nanmax(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((np.size(y_val), np.size(np.unique(y_val)))) #Obtaining features of Class values\n",
    "for i in range(np.shape(y)[0]):\n",
    "    y[i][y_val[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0.] 3\n",
      "[0. 0. 0. 0. 1. 0. 0. 0.] 4\n",
      "[0. 1. 0. 0. 0. 0. 0. 0.] 1\n",
      "[0. 0. 0. 1. 0. 0. 0. 0.] 3\n",
      "[0. 0. 0. 0. 1. 0. 0. 0.] 4\n",
      "[0. 0. 0. 1. 0. 0. 0. 0.] 3\n",
      "[0. 0. 1. 0. 0. 0. 0. 0.] 2\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.] 0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0.] 5\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.] 7\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):       #Class Values and Features\n",
    "    print(y[i], y_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, y_val, ratio):   #Train test split function\n",
    "    split = (len(X) * ratio) // 100\n",
    "    X_train = X[:split]\n",
    "    X_test = X[split:]\n",
    "    y_train = y[:split]\n",
    "    y_test = y[split:]\n",
    "    y_val_train = y_val[:split]\n",
    "    y_val_test = y_val[split:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_val_train, y_val_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_testing, y_train, y_testing, y_val_train, y_val_testing = train_test_split(X, y, y_val, 80)           #Calling Train Test Split function\n",
    "X_test, X_hold, y_test, y_hold, y_val_test, y_val_hold = train_test_split(X_testing, y_testing, y_val_testing, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:        #MLP Classifier class\n",
    "    def __init__(self, X, y_val, Hidden_nodes, lr):            #Initial Function\n",
    "        print(\"MLP Architecture:\\n\")\n",
    "        builder([np.shape(X)[1], Hidden_nodes, np.size(np.unique(y_val))]) #Architecture\n",
    "        self.weights_1 = np.random.randn(np.shape(X)[1], Hidden_nodes)\n",
    "        print(\"\\nInitial Weights 1:\\n\", self.weights_1)\n",
    "        self.weights_2 = np.random.randn(Hidden_nodes, np.size(np.unique(y_val)))\n",
    "        print(\"\\nInitial Weights 2:\\n\", self.weights_2)\n",
    "        \n",
    "        self.lr = [lr]\n",
    "        self.lr_0 = lr\n",
    "        self.error = []\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, z):            #Sigmoid Function.\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def MSE(self, y):                #Mean Squared Error Function\n",
    "        mse = 0\n",
    "        mse = np.sum(np.square(self.y_c - y))/(y.size * 2)\n",
    "        \n",
    "        return mse\n",
    "    \n",
    "    def model_fit(self, X, y, y_val, X_h, y_h, y_val_h, epochs, B_size):    #Model Fit\n",
    "        alpha = 1 / epochs           #alpha for Learning rate decay\n",
    "        min_er = 1.0\n",
    "        self.hold_acc = []\n",
    "        self.train_acc = []\n",
    "        for i in range(epochs):\n",
    "            for j in range(0, np.shape(X)[0], B_size):\n",
    "                y_temp = self.forward_propogation(X[j: j+B_size])      #Forward Propogation Function\n",
    "                self.backward_propogation(X[j:j+B_size], y[j: j+B_size])     #Backward Propogation Function\n",
    "                if j % 10 == 0:\n",
    "                    temp = self.MSE(y[j: j+B_size])\n",
    "                    if temp < min_er:\n",
    "                        optimal_w1 = self.weights_1\n",
    "                        optimal_w2 = self.weights_2\n",
    "                    self.error.append(temp)\n",
    "                    ind = len(self.error)\n",
    "                    self.lr.append(self.lr_0 / math.exp(alpha * i))           #Learning rate decay with constant alpha\n",
    "            self.prediction(X_h, y_h, optimal_w1, optimal_w2)                 #\n",
    "            self.prediction(X, y, optimal_w1, optimal_w2)                     #Predicting and\n",
    "            h_acc = self.accuracy(y_val_h)                                    #Calculating accuracy score \n",
    "            t_acc = self.accuracy(y_val)                                      #for Training and Holdout set\n",
    "            self.hold_acc.append(h_acc)                                       #for every epoch for comparision\n",
    "            self.train_acc.append(t_acc)                                      #\n",
    "            print(\"Epoch:{:5d}\".format(i + 1), end = \" \")                     #\n",
    "            print(\"Training accuracy:{:2.2f}\".format(t_acc), end = \" \")       #\n",
    "            print(\"Holdout accuracy: {:2.2f}\".format(h_acc))                  #\n",
    "        return optimal_w1, optimal_w2\n",
    "                    \n",
    "        \n",
    "    def forward_propogation(self, X):                       #Forward Propogation Function\n",
    "        self.a_1 = np.array(np.dot(X, self.weights_1))\n",
    "        self.h_1 = np.array(self.sigmoid(self.a_1))         #Activation Sigmoid\n",
    "        self.a_2 = np.array(np.dot(self.h_1, self.weights_2))\n",
    "        self.h_2 = np.array(np.tanh(self.a_2))              #Activation Hyperbolic Tangent\n",
    "        self.y_c = self.h_2\n",
    "        return self.y_c\n",
    "    \n",
    "    def backward_propogation(self, X, y):                  #Backward Propogation Function\n",
    "        \n",
    "        Dweights_2 = np.zeros(np.shape(self.weights_2))\n",
    "        \n",
    "        temp = np.multiply((1 - np.square(self.y_c)), (self.y_c - y))\n",
    "        Dweights_2 = np.dot(self.h_1.T, temp)              #Partial Derivative formula for Weights 2\n",
    "        \n",
    "        Dweights_1 = np.zeros(np.shape(self.weights_1))\n",
    "                                                           #Partial Derivative formula for Weights 1\n",
    "        temp = np.dot(self.weights_2, np.multiply((self.y_c - y), np.multiply((1 - self.y_c), self.y_c)).T)\n",
    "        Dweights_1 = np.dot(X.T, np.multiply(temp.T, np.multiply(self.h_1, (1 - self.h_1))))\n",
    "        \n",
    "        ind = len(self.lr) - 1\n",
    "        self.weights_2 = self.weights_2 - (self.lr[ind] * Dweights_2)   #Gradient decent updating Weights\n",
    "        self.weights_1 = self.weights_1 - (self.lr[ind] * Dweights_1)\n",
    "        \n",
    "    def more_forgiving(self, y):            #More Forgiving (1 if >= 0.8)\n",
    "        for i in range(np.size(y)):\n",
    "            if (y[i] >= 0.8):\n",
    "                y[i] = 1.0\n",
    "            elif (y[i] <= 0.2):\n",
    "                y[i] = 0.0\n",
    "            else:\n",
    "                y[i] = 0.5\n",
    "        return y\n",
    "    \n",
    "    def prediction(self, X, y, op_w1, op_w2):      #Prediction function\n",
    "        self.y_pred = np.zeros(np.shape(y))\n",
    "        for i in range(np.shape(X)[0]):\n",
    "            # Forward Propogation for Test input with optimal weights.\n",
    "            a_1 = np.array(np.dot(X[i], op_w1))\n",
    "            h_1 = np.array(self.sigmoid(a_1))\n",
    "            a_2 = np.array(np.dot(h_1, op_w2))\n",
    "            h_2 = np.array(np.tanh(a_2))\n",
    "            y_res = h_2\n",
    "            y_res = np.squeeze(y_res)\n",
    "            self.y_pred[i] = self.more_forgiving(y_res)    #Calling More Forgiving function\n",
    "    \n",
    "    def accuracy(self, y_val):         #Accuracy Calculator\n",
    "        count = 0\n",
    "        acc = 0\n",
    "        for i in range(np.size(y_val)):\n",
    "            pred = -1\n",
    "            y_list = list(self.y_pred[i])\n",
    "            for j in range(len(y_list)):\n",
    "                if (y_list[j] == 1):\n",
    "                    pred = j\n",
    "            if (y_val[i] == pred):\n",
    "                count += 1\n",
    "        acc = (count / np.size(y_val)) * 100\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Architecture:\n",
      "\n",
      "\n",
      "Initial Weights 1:\n",
      " [[-1.18973801e+00 -1.76248511e+00 -1.57070311e-01  8.40471562e-01\n",
      "   5.47961249e-01 -1.32557746e+00 -2.78078101e-01 -7.66496124e-01\n",
      "   6.27485173e-01  5.78127549e-01  6.52884662e-01 -5.44225775e-01]\n",
      " [-1.32784159e+00 -1.35311498e+00  1.30940339e+00 -1.99201957e+00\n",
      "   4.31881084e-01 -2.57753589e+00 -1.09506879e-01 -2.31073711e+00\n",
      "   1.05950255e-01  3.39125353e-01  4.83674613e-01 -1.79590909e+00]\n",
      " [-1.76507239e+00 -1.36810754e-02  5.09177206e-01  3.14694098e-01\n",
      "   1.36813962e-01 -2.98745713e-01  1.63409018e+00  1.36416584e+00\n",
      "   5.84377626e-01  6.29502893e-01 -1.69675671e-01 -5.87456776e-01]\n",
      " [ 1.45355121e-02  4.33063731e-02  9.41523972e-01  4.15037850e-01\n",
      "   1.83784255e+00 -1.57440998e-03  6.53789511e-01 -1.86106779e-01\n",
      "   3.67287933e-01 -1.05328389e-01  3.78082879e-01 -7.95161946e-01]\n",
      " [-1.81770217e+00 -2.09426905e+00 -6.93438212e-01 -2.06447430e+00\n",
      "  -1.88651543e-01  1.03640757e+00 -2.63901662e-01  5.28546360e-01\n",
      "  -8.07578102e-02 -3.83714258e-01  6.91942042e-01  1.86459487e-01]\n",
      " [ 1.50966388e-01  3.49935187e-01 -1.72312247e+00 -4.37401787e-01\n",
      "   1.01531006e-01 -6.06217556e-01 -6.18459769e-01 -1.34067581e-01\n",
      "   3.17017074e-01 -6.31928945e-01  4.03901631e-01  2.17611556e-02]\n",
      " [-5.86507154e-01 -1.10025349e+00  1.79812922e-01  3.53024949e-01\n",
      "   1.33799757e+00 -2.94525901e-01 -1.38136758e+00 -9.76941376e-02\n",
      "   8.52062808e-01  9.59327979e-01 -1.53862716e+00  1.57820345e+00]\n",
      " [ 8.67867059e-02 -3.15489788e-01 -7.57341315e-01  1.53649350e-01\n",
      "   4.04873928e-01 -7.19073097e-01 -3.81814073e-01  2.16494518e+00\n",
      "   2.74098296e-01  2.93936458e-01 -7.32714265e-01  6.15522626e-01]\n",
      " [ 8.30490907e-01 -1.08395316e+00  6.70827563e-01 -1.11630283e+00\n",
      "   8.72353963e-01  6.93335017e-01  9.41452892e-01  6.61523852e-01\n",
      "  -9.15019774e-01 -1.48965495e+00 -9.98934419e-01  2.52227052e-01]\n",
      " [ 8.39077200e-01 -4.81026376e-01 -4.64884345e-01  7.84929528e-01\n",
      "   1.14614869e+00  9.09022949e-01  1.24582767e-02  5.99193926e-01\n",
      "   2.67867265e-01 -1.41350432e+00 -9.98106081e-02  1.00026398e+00]]\n",
      "\n",
      "Initial Weights 2:\n",
      " [[-0.53644567 -0.50711356 -1.01269175  0.57645773  2.13545462 -1.30979176\n",
      "   1.06827612  0.1546655 ]\n",
      " [-1.87792469  1.42705146 -0.14415239  0.44398561 -0.29198684  2.02854259\n",
      "  -0.30410748  0.74035617]\n",
      " [-1.33397901 -0.59042688  0.54900045  0.72017615 -2.17401172 -0.34840577\n",
      "   0.26796919  0.05568989]\n",
      " [ 0.15091672 -0.9213747   0.38580349  0.67114474 -0.47611668  1.19907639\n",
      "  -0.03647108 -0.17637123]\n",
      " [ 0.32155514  2.21687199 -0.80840892  0.59744539 -1.84381342 -0.08586004\n",
      "  -1.40390164  0.18584508]\n",
      " [ 0.42054243  1.92490541  1.99429405 -0.89926555  1.17067307 -1.47694992\n",
      "  -0.8054588   0.59863383]\n",
      " [-0.01606995 -0.16999246  0.56249364 -0.07630743 -0.18754011 -0.17806948\n",
      "  -0.13770817  1.01795234]\n",
      " [ 0.50932187  0.60892988  1.67387911 -1.31552422 -1.13423574  0.60772166\n",
      "  -0.35974789 -0.36055545]\n",
      " [ 0.95657115 -1.02100909 -0.19908478  0.38000479 -0.24505447  0.92115108\n",
      "  -0.39372259 -1.75493669]\n",
      " [-0.37599725  1.95422566 -0.96648366  0.2745087  -1.18162945 -0.0681424\n",
      "   0.47235774 -1.20125484]\n",
      " [-0.38883439  2.0730327   0.71248211 -0.06177116  1.69073543  1.29584415\n",
      "   0.63197222  0.62146807]\n",
      " [ 0.45637724 -0.72632633  0.60541872  0.4586971  -0.44484857 -0.70936128\n",
      "   1.25127464  0.81367927]]\n",
      "\n",
      "Training.....\n",
      "Epoch:    1 Training accuracy:0.00 Holdout accuracy: 0.00\n",
      "Epoch:    2 Training accuracy:4.38 Holdout accuracy: 0.00\n",
      "Epoch:    3 Training accuracy:5.00 Holdout accuracy: 0.00\n",
      "Epoch:    4 Training accuracy:9.38 Holdout accuracy: 15.00\n",
      "Epoch:    5 Training accuracy:9.38 Holdout accuracy: 15.00\n",
      "Epoch:    6 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:    7 Training accuracy:9.38 Holdout accuracy: 15.00\n",
      "Epoch:    8 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:    9 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:   10 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:   11 Training accuracy:9.38 Holdout accuracy: 15.00\n",
      "Epoch:   12 Training accuracy:20.62 Holdout accuracy: 25.00\n",
      "Epoch:   13 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:   14 Training accuracy:10.62 Holdout accuracy: 20.00\n",
      "Epoch:   15 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:   16 Training accuracy:20.62 Holdout accuracy: 25.00\n",
      "Epoch:   17 Training accuracy:5.00 Holdout accuracy: 0.00\n",
      "Epoch:   18 Training accuracy:5.00 Holdout accuracy: 0.00\n",
      "Epoch:   19 Training accuracy:9.38 Holdout accuracy: 15.00\n",
      "Epoch:   20 Training accuracy:1.25 Holdout accuracy: 0.00\n",
      "Epoch:   21 Training accuracy:0.00 Holdout accuracy: 0.00\n",
      "Epoch:   22 Training accuracy:6.25 Holdout accuracy: 0.00\n",
      "Epoch:   23 Training accuracy:4.38 Holdout accuracy: 0.00\n",
      "Epoch:   24 Training accuracy:0.00 Holdout accuracy: 0.00\n",
      "Epoch:   25 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:   26 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:   27 Training accuracy:0.00 Holdout accuracy: 0.00\n",
      "Epoch:   28 Training accuracy:13.12 Holdout accuracy: 10.00\n",
      "Epoch:   29 Training accuracy:0.00 Holdout accuracy: 0.00\n",
      "Epoch:   30 Training accuracy:11.88 Holdout accuracy: 5.00\n",
      "\n",
      "Final Weights 1:\n",
      " [[-2.5283849   0.565996    1.9736802   2.63187956  1.9810143  -2.67060729\n",
      "   0.6575405   1.30052811  1.97331223  2.43169435 -1.50964498  0.79425868]\n",
      " [-2.63957488  0.79736971  3.21113547  0.14032192  1.8156449  -3.70329766\n",
      "   0.83955282 -0.11866537  1.48097821  2.21373523 -1.64311546 -0.46704418]\n",
      " [-2.8168038   2.23905184  2.34087318  2.09197     1.47951486 -1.6312458\n",
      "   2.66692626  2.68979556  1.79489307  2.24748647 -1.97358569  0.88902816]\n",
      " [-1.43396962  2.01604861  2.57990765  1.99853312  2.67337257 -1.5447374\n",
      "   1.60914246  1.35095364  1.51083223  1.8555124  -1.35788879  0.58270695]\n",
      " [-3.2926887   0.09756813  1.59066249  0.19675293  1.37074416 -1.08523815\n",
      "   0.98928665  2.17028398  1.39581462  1.97682727 -1.44219957  1.66078231]\n",
      " [-1.29295155  2.43710472  0.51208813  1.37339722  1.25489761 -1.83575286\n",
      "   0.31197408  1.40780758  1.50056344  1.28303187 -1.39497811  1.09090603]\n",
      " [-1.76366863  0.91865375  1.77544781  1.97263857  2.24828138 -1.60533132\n",
      "  -0.40303481  1.51139091  1.97358075  2.51073416 -2.87569135  2.61744183]\n",
      " [-1.34841079  1.82261043  1.39764866  1.99794789  1.71807031 -2.02805098\n",
      "   0.69751993  3.44098681  1.5376876   2.10294976 -2.53914525  1.82613432]\n",
      " [-0.97285348  1.02744022  2.55749393  0.85992164  2.0976701  -1.22009178\n",
      "   2.26541539  2.16734278  0.54199956  0.84445168 -2.68079213  1.77882404]\n",
      " [-1.0187926   1.74555008  1.74489114  2.59178713  2.35074221 -1.04847459\n",
      "   1.11764825  2.15584145  1.58247914  0.93573981 -2.03525005  2.27083623]]\n",
      "\n",
      "Final Weights 2:\n",
      " [[-0.53659238 -0.53329876 -0.98739368  0.54933513  2.1372733  -1.35058775\n",
      "   1.0786444   0.20038299]\n",
      " [-1.70630844  1.12741564 -0.42102502  0.31677531 -0.29110764  1.457586\n",
      "  -0.34250528  0.59310704]\n",
      " [-1.19689315 -0.83669644  0.61594397  0.34951612 -2.17040528 -0.7250083\n",
      "   0.45189771  0.1097823 ]\n",
      " [ 0.35909574 -0.94317697  0.3539194   0.45248452 -0.47310088  0.75508432\n",
      "  -0.21353217 -0.21751895]\n",
      " [ 0.35467445  1.9469314  -0.84215653  0.20634298 -1.83462559 -0.57608025\n",
      "  -1.08998215  0.45106797]\n",
      " [ 0.44552878  1.88846519  1.9757902  -0.94184824  1.17335091 -1.45960471\n",
      "  -0.75530168  0.62752208]\n",
      " [ 0.01012277 -0.33010273 -0.07107258 -0.14687491 -0.18194937 -0.48711586\n",
      "   0.51586196  0.77955147]\n",
      " [ 0.64912868  0.41946917  1.59481118 -1.68443546 -1.12628683  0.21365895\n",
      "  -0.08942456 -0.19714344]\n",
      " [ 1.03107833 -1.23019162 -0.25538013  0.03086808 -0.23776259  0.47550394\n",
      "  -0.16139286 -1.54960181]\n",
      " [-0.24527672  1.72263665 -0.87259851 -0.0100657  -1.1783193  -0.47459066\n",
      "   0.61992422 -1.20374497]\n",
      " [-0.48169406  2.02902883  0.70246636 -0.11372823  1.69532082  1.18640526\n",
      "   0.76624502  0.7577846 ]\n",
      " [ 0.53212125 -0.6913563   0.26512906  0.35670127 -0.4399278  -0.84443729\n",
      "   1.28703735  0.87397136]]\n",
      "\n",
      "Accuracy Testing Data:15.00\n"
     ]
    }
   ],
   "source": [
    "jakh = ANN(X_train, y_val_train, 12, 0.1)  #Assigning Class\n",
    "print(\"\\nTraining.....\")\n",
    "w1, w2 = jakh.model_fit(X_train, y_train, y_val_train, X_hold, y_hold, y_val_hold, 30, 10)\n",
    "jakh.prediction(X_test, y_test, w1, w2)\n",
    "print(\"\\nFinal Weights 1:\\n\", w1)\n",
    "print(\"\\nFinal Weights 2:\\n\", w2)\n",
    "print(\"\\nAccuracy Testing Data:{:4.2f}\".format(jakh.accuracy(y_val_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
